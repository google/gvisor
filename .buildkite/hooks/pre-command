set -euo pipefail

# Download any build-specific configuration that has been uploaded.
# This allows top-level steps to override all subsequent steps.
buildkite-agent artifact download 'tools/bazeldefs/*' . || true

# Install packages we need. Docker must be installed and configured,
# as should Go itself. We just install some extra bits and pieces.
function install_pkgs() {
  export DEBIAN_FRONTEND=noninteractive
  while true; do
    if sudo -E apt-get update -q && sudo -E apt-get install -qy "$@"; then
      break
    fi
  done
}
install_pkgs make linux-libc-dev graphviz jq curl binutils gnupg gnupg-agent \
  gcc pkg-config apt-transport-https ca-certificates \
  software-properties-common rsync kmod systemd

# Install headers, only if available.
if test -n "$(apt-cache search --names-only "^linux-headers-$(uname -r)$")"; then
  install_pkgs "linux-headers-$(uname -r)"
elif test -n "$(apt-cache search --names-only "^linux-gcp-headers-$(uname -r | cut -d- -f1-2)$")"; then
  install_pkgs "linux-gcp-headers-$(uname -r | cut -d- -f1-2)"
fi

set -x

# Setup for parallelization with PARTITION and TOTAL_PARTITIONS.
export PARTITION=${BUILDKITE_PARALLEL_JOB:-0}
PARTITION=$((${PARTITION}+1)) # 1-indexed, but PARALLEL_JOB is 0-indexed.
export TOTAL_PARTITIONS=${BUILDKITE_PARALLEL_JOB_COUNT:-1}

# Set the system-wide Docker runtime name after the BuildKite branch name.
# Remove any slashes and other characters that are not supported in Docker
# runtime names. The runtime name must be a single valid path component.
export RUNTIME="buildkite_runtime_${BUILDKITE_BRANCH}-${BUILDKITE_BUILD_ID}"
export RUNTIME="$(echo "$RUNTIME" | sed -r 's~[^-_a-z0-9]+~_~g')"

# If running in a container, set the reload command appropriately.
if [[ -x /tmp/buildkite-reload-host-docker/reload ]]; then
  export DOCKER_RELOAD_COMMAND='/tmp/buildkite-reload-host-docker/reload'
else
  export DOCKER_RELOAD_COMMAND='sudo systemctl reload docker'
fi

# Ensure Docker has experimental enabled, install runtimes.
HAD_EXPERIMENTAL="$(docker version --format='{{.Server.Experimental}}')"
if [[ -n "${STAGED_BINARIES:-}" ]]; then
  # Used `runsc` from STAGED_BINARIES instead of building it from scratch.
  export BUILDKITE_STAGED_BINARIES_DIRECTORY="$(mktemp -d)"
  gsutil cat "$STAGED_BINARIES" \
    | tar -C "$BUILDKITE_STAGED_BINARIES_DIRECTORY" -zxvf - runsc
  chmod +x "$BUILDKITE_STAGED_BINARIES_DIRECTORY/runsc"
  sudo "$BUILDKITE_STAGED_BINARIES_DIRECTORY/runsc" install \
    --experimental=true --runtime="${RUNTIME}" \
    -- "${RUNTIME_ARGS:-}"
else
  make sudo TARGETS=//runsc:runsc \
    ARGS="install --experimental=true --runtime=${RUNTIME} -- ${RUNTIME_ARGS:-}"
fi
if [[ "$HAD_EXPERIMENTAL" == false ]]; then
  # WARNING: We may be running in a container when this command executes.
  # This only makes sense if Docker's `live-restore` feature is enabled.
  sudo systemctl restart docker
else
  # If experimental-ness was already enabled, we don't need to restart, as the
  # only thing we modified is the list of runtimes, which can be reloaded with
  # just a SIGHUP.
  bash -c "$DOCKER_RELOAD_COMMAND"
fi

# Helper for benchmarks, based on the branch.
if test "${BUILDKITE_BRANCH}" = "master"; then
  export BENCHMARKS_OFFICIAL=true
else
  export BENCHMARKS_OFFICIAL=false
fi

# Clear existing profiles.
sudo rm -rf /tmp/profile

# Allow to read dmesg for all users. It is required for the syslog test.
sudo sysctl -w kernel.dmesg_restrict=0

# Download credentials, if a release agent.
if test "${BUILDKITE_AGENT_META_DATA_QUEUE}" = "release"; then
  # Pull down secrets.
  gcloud secrets versions access --secret="repo-key" --format='get(payload.data)' latest | tr '_-' '/+' | base64 -d  > repo.key

  # Configure the Docker credential helper (to push images).
  gcloud auth configure-docker -q
fi
